# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D8ctulUdkWHKSogm3LlzmzrOL9y5M53r
"""

!pip install  pandas openpyxl matplotlib
!pip install google-generativeai PyMuPDF fpdf

import google.generativeai as genai

genai.configure(api_key="Your Gemini API")

model = genai.GenerativeModel("gemini-2.0-flash")

from google.colab import files
uploaded = files.upload()

universal_prompt = """
You are an AI assistant designed to extract structured educational content from NCERT Grade 8 Science textbooks.

Please extract the following:
- Chapter Name
- Topic Name
- Sub-topic Name
- Paragraphs
- Activities
- Images (Caption only)
- Diagrams
- Tables
- Examples
- Exercises
- Questions
- Boxed Facts or External References

Output should be in JSON with this structure:
{
  "chapter": "Chapter Name",
  "topics": [
    {
      "topic_name": "Topic 1",
      "subtopics": [
        {
          "subtopic_name": "Subtopic A",
          "content": {
            "paragraphs": [...],
            "activities": [...],
            "tables": [...],
            "images": [...],
            "questions": [...]
          }
        }
      ]
    }
  ]
}
ONLY extract content. Do not summarize.
"""

import fitz  # PyMuPDF
pdf_url = "hesc107.pdf"
def extract_text_from_pdf(pdf_url):
    text = ""
    doc = fitz.open(pdf_url)
    for page in doc:
        text += page.get_text()
    return text


chapter_text = extract_text_from_pdf(pdf_url)
response = model.generate_content(universal_prompt + chapter_text[:500000])  # limit characters
extracted_json = response.text  # or .parts[0].text if needed

print(extracted_json)  # print first 500 characters

# STEP 1: Clean response output
cleaned_output = extracted_json.strip()

# Remove markdown code block syntax if it exists
if cleaned_output.startswith("```json"):
    cleaned_output = cleaned_output.replace("```json", "").strip()
if cleaned_output.endswith("```"):
    cleaned_output = cleaned_output[:-3].strip()

# Optional: Preview before parsing
print(cleaned_output[:500])  # Preview first 500 characters

# STEP 2: Parse JSON
import json

try:
    extracted = json.loads(cleaned_output)
    print("‚úÖ JSON parsed successfully!")
except json.JSONDecodeError as e:
    print("‚ùå Still not valid JSON:", e)
with open("chapter-extract.json", "w") as f:
    json.dump(extracted, f, indent=2)
import pandas as pd

def json_to_excel(json_file, excel_file):
    with open(json_file) as f:
        data = json.load(f)

    rows = []
    for topic in data["topics"]:
        for sub in topic["subtopics"]:
            content = sub["content"]

            # Convert lists of dicts to string summaries
            def format_items(item_list):
                if isinstance(item_list, list) and all(isinstance(i, dict) for i in item_list):
                    return "\n".join(f"{i.get('title', '')}: {i.get('description', '')}" for i in item_list)
                elif isinstance(item_list, list):
                    return "\n".join(str(i) for i in item_list)
                return ""

            row = {
                "Chapter": data["chapter"],
                "Topic": topic["topic_name"],
                "Subtopic": sub["subtopic_name"],
                "Paragraphs": format_items(content.get("paragraphs", [])),
                "Activities": format_items(content.get("activities", [])),
                "Questions": format_items(content.get("questions", []))
            }
            rows.append(row)

    df = pd.DataFrame(rows)
    df.to_excel(excel_file, index=False)

json_to_excel("chapter-extract.json", "chapter-output.xlsx")

planner_prompt = """
You are an educational assistant. Given the extracted topics from an NCERT Science chapter and a number of study days, create a structured day-wise teaching plan.

Input:
- Chapter: {chapter_name}
- Topics: {topic_list}
- Total Days: {user_days}

Output:
- Day-wise plan (in table form or bullet points)
- Each day should include topic, sub-topic, estimated duration

Ensure the plan fits the provided total days.
Dont provide extracted chapter again,only provide the plan.
--- BEGIN CHAPTER CONTENT ---
"""

response = model.generate_content(planner_prompt+ cleaned_output)  # limit characters
extracted = response.text
print(extracted)

from fpdf import FPDF

def save_study_plan_to_pdf(study_text, output_file="study_planner.pdf"):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.set_font("Arial", size=12)

    # Split by lines and write each
    for line in study_text.splitlines():
        pdf.multi_cell(0, 10, line)

    pdf.output(output_file)
    print(f"‚úÖ Study planner saved as: {output_file}")
save_study_plan_to_pdf(extracted, "study_planner.pdf")

def generate_text_knowledge_graph(json_file, output_file="knowledge_graph.txt"):
    with open(json_file) as f:
        data = json.load(f)

    lines = []

    chapter = data.get("chapter", "Unknown Chapter")
    lines.append(f"üìò Chapter: {chapter}")

    for topic in data.get("topics", []):
        topic_name = topic.get("topic_name", "Unnamed Topic")
        lines.append(f"  ‚îú‚îÄ üìë Topic: {topic_name}")

        for sub in topic.get("subtopics", []):
            subtopic_name = sub.get("subtopic_name") or "Unnamed Sub-topic"
            lines.append(f"  ‚îÇ   ‚îú‚îÄ üîπ Sub-topic: {subtopic_name}")

            content = sub.get("content", {})
            for content_type in ["paragraphs", "activities", "tables", "images", "questions"]:
                items = content.get(content_type)
                if items:
                    lines.append(f"  ‚îÇ   ‚îÇ   ‚îú‚îÄ üîó {content_type.capitalize()}: {len(items)} item(s)")

    # Save or print
    output = "\n".join(lines)
    with open(output_file, "w") as f:
        f.write(output)
    print(output)  # Also show in notebook/terminal
generate_text_knowledge_graph("chapter-extract.json")
